{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name /Users/bytedance/.cache/torch/sentence_transformers/nghuyong_ernie-1.0. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /Users/bytedance/.cache/torch/sentence_transformers/nghuyong_ernie-1.0 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('nghuyong/ernie-1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "火把接力传递 \t\t 意思是给它一把火烧光，指用火烧毁 \t\t Score: 0.7910\n",
      "火把接力传递 \t\t 意思是无处安身，四处流浪 \t\t Score: 0.6727\n",
      "火把接力传递 \t\t 意思为焚烧毁坏 \t\t Score: 0.7152\n"
     ]
    }
   ],
   "source": [
    "# Two lists of sentences\n",
    "sentences1 = ['火把接力传递',\n",
    "             '火把接力传递',\n",
    "             '火把接力传递']\n",
    "\n",
    "sentences2 = ['意思是给它一把火烧光，指用火烧毁',\n",
    "              '意思是无处安身，四处流浪',\n",
    "              '意思为焚烧毁坏']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "wiki_info = json.load(open('data/wiki_info_v2.json'))\n",
    "train_csv = pd.read_csv('data/train.csv')\n",
    "valid_csv = pd.read_csv('data/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, wiki_info):\n",
    "    questions = []\n",
    "    contexts = []\n",
    "    labels = []\n",
    "    for idx, row in data.iterrows():\n",
    "        questions.append(f'{row[\"riddle\"]}')\n",
    "        labels.append(int(row['label']))\n",
    "        context = []\n",
    "        for i in range(5):\n",
    "            name = f'choice{i}'\n",
    "            explanation = wiki_info.get(row[name], '')\n",
    "            context.append(explanation)\n",
    "        contexts.append(context)\n",
    "    return questions, contexts, labels\n",
    "\n",
    "questions, contexts, labels = preprocess(valid_csv, wiki_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7975]])\n",
      "tensor([[0.7455]])\n",
      "tensor([[0.7235]])\n",
      "tensor([[0.6748]])\n",
      "tensor([[0.7766]])\n",
      "tensor([[0.7946]])\n",
      "tensor([[0.7972]])\n",
      "tensor([[0.6897]])\n",
      "tensor([[0.7861]])\n",
      "tensor([[0.7462]])\n",
      "tensor([[0.7173]])\n",
      "tensor([[0.7490]])\n",
      "tensor([[0.6997]])\n",
      "tensor([[0.7245]])\n",
      "tensor([[0.7334]])\n",
      "tensor([[0.7965]])\n",
      "tensor([[0.7963]])\n",
      "tensor([[0.8142]])\n",
      "tensor([[0.8039]])\n",
      "tensor([[0.7886]])\n",
      "tensor([[0.8527]])\n",
      "tensor([[0.8385]])\n",
      "tensor([[0.8214]])\n",
      "tensor([[0.7936]])\n",
      "tensor([[0.8051]])\n",
      "tensor([[0.8336]])\n",
      "tensor([[0.8473]])\n",
      "tensor([[0.8255]])\n",
      "tensor([[0.8632]])\n",
      "tensor([[0.8509]])\n",
      "tensor([[0.8445]])\n",
      "tensor([[0.8092]])\n",
      "tensor([[0.8192]])\n",
      "tensor([[0.8080]])\n",
      "tensor([[0.8400]])\n",
      "tensor([[0.8122]])\n",
      "tensor([[0.7877]])\n",
      "tensor([[0.8024]])\n",
      "tensor([[0.7919]])\n",
      "tensor([[0.8442]])\n",
      "tensor([[0.7709]])\n",
      "tensor([[0.7852]])\n",
      "tensor([[0.7822]])\n",
      "tensor([[0.7746]])\n",
      "tensor([[0.7600]])\n",
      "tensor([[0.6198]])\n",
      "tensor([[0.5840]])\n",
      "tensor([[0.7055]])\n",
      "tensor([[0.7192]])\n",
      "tensor([[0.7346]])\n",
      "tensor([[0.7734]])\n",
      "tensor([[0.7501]])\n",
      "tensor([[0.7750]])\n",
      "tensor([[0.7928]])\n",
      "tensor([[0.7302]])\n",
      "tensor([[0.7833]])\n",
      "tensor([[0.7307]])\n",
      "tensor([[0.7500]])\n",
      "tensor([[0.7073]])\n",
      "tensor([[0.7642]])\n",
      "tensor([[0.8316]])\n",
      "tensor([[0.8148]])\n",
      "tensor([[0.8448]])\n",
      "tensor([[0.8143]])\n",
      "tensor([[0.8188]])\n",
      "tensor([[0.7496]])\n",
      "tensor([[0.7363]])\n",
      "tensor([[0.7614]])\n",
      "tensor([[0.7650]])\n",
      "tensor([[0.6611]])\n",
      "tensor([[0.7276]])\n",
      "tensor([[0.7440]])\n",
      "tensor([[0.7142]])\n",
      "tensor([[0.7012]])\n",
      "tensor([[0.7477]])\n",
      "tensor([[0.7702]])\n",
      "tensor([[0.7630]])\n",
      "tensor([[0.7229]])\n",
      "tensor([[0.8110]])\n",
      "tensor([[0.7221]])\n",
      "tensor([[0.7887]])\n",
      "tensor([[0.7832]])\n",
      "tensor([[0.7491]])\n",
      "tensor([[0.7466]])\n",
      "tensor([[0.7883]])\n",
      "tensor([[0.7107]])\n",
      "tensor([[0.8046]])\n",
      "tensor([[0.7081]])\n",
      "tensor([[0.7690]])\n",
      "tensor([[0.7249]])\n",
      "tensor([[0.8082]])\n",
      "tensor([[0.8440]])\n",
      "tensor([[0.8555]])\n",
      "tensor([[0.8365]])\n",
      "tensor([[0.8575]])\n",
      "tensor([[0.8542]])\n",
      "tensor([[0.8542]])\n",
      "tensor([[0.8301]])\n",
      "tensor([[0.8642]])\n",
      "tensor([[0.7774]])\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "\n",
    "for context, question, label in zip(contexts, questions, labels):\n",
    "    pred = 0\n",
    "    val = 0\n",
    "    for idx, text in enumerate(context):\n",
    "        embeddings1 = model.encode(question, convert_to_tensor=True)\n",
    "        embeddings2 = model.encode(text, convert_to_tensor=True)\n",
    "        score = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "        if score > val:\n",
    "            pred = idx\n",
    "            val = score\n",
    "    tp += (pred == label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}